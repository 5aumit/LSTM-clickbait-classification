{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "#from gensim.summarization import keywords\n",
    "#import preprocessor as p\n",
    "import texthero as hero\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_text as text\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clickbait/clickbait_data.csv')\n",
    "df = df.sample(frac = 1,random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>How Well Do You Remember \"The Nightmare Before...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Which Is Better: \"Hocus Pocus\" Or \"Halloweentown\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12472</th>\n",
       "      <td>Tell Us About Yourself(ie): Luke Bryan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18616</th>\n",
       "      <td>NASA's Mars rovers exceed all expectations</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10067</th>\n",
       "      <td>19 Adorable Lingerie Sets To Wear On Valentine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  clickbait\n",
       "5941   How Well Do You Remember \"The Nightmare Before...          1\n",
       "684    Which Is Better: \"Hocus Pocus\" Or \"Halloweentown\"          1\n",
       "12472             Tell Us About Yourself(ie): Luke Bryan          1\n",
       "18616         NASA's Mars rovers exceed all expectations          0\n",
       "10067  19 Adorable Lingerie Sets To Wear On Valentine...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5941        well remember nightmare christmas\n",
       "684          better hocus pocus halloweentown\n",
       "12472                   tell us ie luke bryan\n",
       "18616    nasa mars rovers exceed expectations\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use texthero to clean data in one go\n",
    "\n",
    "df['headline'] = hero.clean(df['headline'])\n",
    "df['headline'][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['headline'], df['clickbait'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12015\n",
       "0    11985\n",
       "Name: clickbait, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(text):\n",
    "    preprocessed = bert_preprocess(text)\n",
    "    return bert_encoder(preprocessed)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-0.7772485 , -0.3398778 , -0.3659275 ,  0.58366   ,  0.31049612,\n",
       "        -0.10770843,  0.70381814,  0.2029457 , -0.2316289 , -0.99983853,\n",
       "        -0.38446948,  0.60503167,  0.97788596,  0.07288127,  0.86847544,\n",
       "        -0.4598918 , -0.1169603 , -0.5443887 ,  0.20859379, -0.37066644,\n",
       "         0.56139916,  0.99768436,  0.19245009,  0.2572987 ,  0.5108195 ,\n",
       "         0.83992726, -0.56694853,  0.8888596 ,  0.94153   ,  0.6475518 ,\n",
       "        -0.54680526,  0.1072831 , -0.9885101 , -0.09085421, -0.5295646 ,\n",
       "        -0.98854864,  0.31841645, -0.68289536,  0.03286978,  0.169518  ,\n",
       "        -0.88812697,  0.20929658,  0.9995327 , -0.05376754,  0.17120354,\n",
       "        -0.1565725 , -0.9999703 ,  0.21230058, -0.84628356,  0.1325828 ,\n",
       "         0.43749017,  0.08387292,  0.15171152,  0.3945125 ,  0.3373591 ,\n",
       "         0.05389988, -0.2250249 ,  0.11121577, -0.13990155, -0.5157387 ,\n",
       "        -0.6130257 ,  0.40843183, -0.658992  , -0.84319955,  0.5922122 ,\n",
       "         0.16166519, -0.09735344, -0.32923856,  0.03937905, -0.00195072,\n",
       "         0.6815707 ,  0.16239785,  0.47658956, -0.79465276,  0.10918906,\n",
       "         0.31149608, -0.4702798 ,  1.        , -0.36019963, -0.9794267 ,\n",
       "         0.4307608 ,  0.00935943,  0.4602065 ,  0.13523094, -0.00353935,\n",
       "        -0.99999964,  0.3662041 , -0.12124979, -0.98632413,  0.16730149,\n",
       "         0.6039133 , -0.12555148, -0.35932726,  0.43167067, -0.44100118,\n",
       "        -0.37580487, -0.10304413, -0.4346476 , -0.23989509, -0.49726835,\n",
       "        -0.00188297, -0.21417475, -0.06765174, -0.3405124 ,  0.41689566,\n",
       "        -0.37076727, -0.24507375, -0.10015696, -0.20022063,  0.61452943,\n",
       "         0.16646658, -0.40689427,  0.44840008, -0.93739295,  0.60519296,\n",
       "        -0.23079848, -0.9843442 , -0.47626865, -0.9908038 ,  0.6505049 ,\n",
       "        -0.31069863, -0.35808775,  0.8948287 ,  0.17593434,  0.22004871,\n",
       "         0.0484811 , -0.02335741, -1.        , -0.5509144 , -0.45948094,\n",
       "         0.20392618, -0.24154326, -0.9754768 , -0.9465361 ,  0.6014289 ,\n",
       "         0.90804446,  0.06265035,  0.9984839 , -0.1884486 ,  0.8977193 ,\n",
       "         0.16737203, -0.3013742 ,  0.01594542, -0.43547067,  0.5635905 ,\n",
       "        -0.05272634, -0.38991958,  0.24006502, -0.03047107, -0.06210297,\n",
       "        -0.23221752, -0.16155341, -0.3779853 , -0.93017983, -0.20862345,\n",
       "         0.91355264, -0.08780397, -0.47969788,  0.34222862, -0.2873083 ,\n",
       "        -0.34439525,  0.7308889 ,  0.5522651 ,  0.26225576, -0.24889308,\n",
       "         0.2105927 , -0.18920112,  0.4673433 , -0.5838301 ,  0.24303195,\n",
       "         0.30770707, -0.16099171, -0.3510438 , -0.975623  , -0.36044124,\n",
       "         0.32199523,  0.9870487 ,  0.5253632 ,  0.26798663,  0.02462151,\n",
       "        -0.27606705,  0.3446984 , -0.9381641 ,  0.9790366 , -0.21541399,\n",
       "         0.31175554,  0.03488637, -0.2677935 , -0.7431381 , -0.2694484 ,\n",
       "         0.6931165 , -0.22095549, -0.74831176, -0.05930692, -0.46989092,\n",
       "        -0.35634434, -0.42425835,  0.21468972, -0.28854033, -0.3453281 ,\n",
       "        -0.09294579,  0.9028797 ,  0.8807118 ,  0.70925915, -0.22574778,\n",
       "         0.60704285, -0.8212864 , -0.35103697,  0.11089928,  0.28071967,\n",
       "         0.27397254,  0.99048424, -0.46970016, -0.05140802, -0.8501538 ,\n",
       "        -0.97830075,  0.02553752, -0.90556663, -0.03815051, -0.5895576 ,\n",
       "         0.4620242 ,  0.16861106, -0.04569049,  0.23360242, -0.8883319 ,\n",
       "        -0.6983911 ,  0.31486717, -0.28017122,  0.38204625, -0.23484556,\n",
       "         0.8384834 ,  0.64035016, -0.4182573 ,  0.51077735,  0.91174793,\n",
       "        -0.04613866, -0.78014797,  0.65284264, -0.18447866,  0.6060321 ,\n",
       "        -0.50619274,  0.9727392 ,  0.4773297 ,  0.48622668, -0.9123348 ,\n",
       "         0.00828233, -0.70498794, -0.13034776, -0.24212113, -0.464207  ,\n",
       "         0.44375256,  0.36470488,  0.4122105 ,  0.6556758 , -0.5186919 ,\n",
       "         0.9567819 , -0.827616  , -0.9653723 , -0.71686375, -0.02504322,\n",
       "        -0.9910519 ,  0.5570731 ,  0.37789425, -0.08799133, -0.40715718,\n",
       "        -0.3792524 , -0.9606927 ,  0.7097514 ,  0.05004722,  0.90948635,\n",
       "        -0.2488843 , -0.8412197 , -0.3756749 , -0.94228715, -0.10173505,\n",
       "        -0.15388806, -0.04351063, -0.20666967, -0.8911985 ,  0.5742234 ,\n",
       "         0.39709386,  0.22621289, -0.2190785 ,  0.98398906,  0.99998707,\n",
       "         0.9698565 ,  0.8620991 ,  0.4926165 , -0.99381095, -0.52200186,\n",
       "         0.99989897, -0.8552325 , -0.9999989 , -0.8887189 , -0.60078675,\n",
       "         0.23729458, -1.        ,  0.01934711, -0.0126382 , -0.8984477 ,\n",
       "         0.15554246,  0.974622  ,  0.9558463 , -1.        ,  0.7309107 ,\n",
       "         0.88364434, -0.52779436,  0.68649334, -0.18674372,  0.96549284,\n",
       "         0.37165362,  0.535436  , -0.05573677,  0.41537473, -0.79218453,\n",
       "        -0.78256   ,  0.01089036, -0.1629919 ,  0.943532  ,  0.25316897,\n",
       "        -0.5576788 , -0.8620906 ,  0.16366681, -0.075289  ,  0.03879467,\n",
       "        -0.9518892 , -0.17330392,  0.03250935,  0.5762282 ,  0.04309723,\n",
       "         0.05903836, -0.5747009 ,  0.21302296, -0.4242126 ,  0.15757163,\n",
       "         0.50393844, -0.9020122 , -0.2562605 , -0.5779289 , -0.4223902 ,\n",
       "        -0.15953863, -0.9503836 ,  0.9509026 , -0.18398055,  0.34166497,\n",
       "         1.        ,  0.19567989, -0.7573398 ,  0.45998883,  0.27952418,\n",
       "        -0.20526443,  1.        ,  0.6572424 , -0.9818871 , -0.31725338,\n",
       "         0.3581536 , -0.5190246 , -0.5178705 ,  0.99761826, -0.32491598,\n",
       "        -0.34426656,  0.2239959 ,  0.98751503, -0.9932081 ,  0.83371466,\n",
       "        -0.69501084, -0.9410149 ,  0.93759227,  0.91887593, -0.43054226,\n",
       "        -0.55587965, -0.00480556,  0.01201974,  0.28073123, -0.8617483 ,\n",
       "         0.34085828,  0.41489315, -0.08473229,  0.87213343, -0.71432275,\n",
       "        -0.42392838,  0.32607558, -0.33471298,  0.36593744,  0.31105334,\n",
       "         0.44848356, -0.22718024, -0.14722596, -0.43251282, -0.6162798 ,\n",
       "        -0.9201349 ,  0.09039612,  1.        , -0.06003945,  0.27856854,\n",
       "         0.04324845, -0.0868683 , -0.13545278,  0.3986006 ,  0.48248732,\n",
       "        -0.22875442, -0.66301626,  0.19496556, -0.8722594 , -0.99007696,\n",
       "         0.6651071 ,  0.2747341 , -0.2813901 ,  0.9995442 ,  0.40004882,\n",
       "         0.23668963, -0.1130355 ,  0.82716376, -0.04112689,  0.21400912,\n",
       "         0.4087185 ,  0.97623944, -0.309595  ,  0.4905467 ,  0.52837604,\n",
       "        -0.5018647 , -0.3347259 , -0.5104951 ,  0.14945854, -0.9139934 ,\n",
       "         0.09059305, -0.9284414 ,  0.9590533 ,  0.45217574,  0.33314213,\n",
       "         0.12409579,  0.37681904,  1.        , -0.78694606,  0.5248964 ,\n",
       "        -0.14870648,  0.6504803 , -0.97883606, -0.42008838, -0.3517525 ,\n",
       "        -0.07205387, -0.26029927, -0.22751975,  0.15388855, -0.9537554 ,\n",
       "         0.23058482,  0.09033466, -0.91985476, -0.989775  ,  0.1788699 ,\n",
       "         0.6021428 ,  0.01531544, -0.83513814, -0.5437054 , -0.44186816,\n",
       "         0.3488633 , -0.28326118, -0.9151039 ,  0.38961366, -0.22653943,\n",
       "         0.37765265, -0.20870768,  0.522905  ,  0.18237108,  0.8721186 ,\n",
       "        -0.16049391, -0.11546005, -0.10465486, -0.65122527,  0.75534636,\n",
       "        -0.6701698 , -0.2955044 , -0.11027381,  1.        , -0.32570758,\n",
       "         0.54636085,  0.55039006,  0.52156115, -0.19003575,  0.25139886,\n",
       "         0.44441307,  0.23979035, -0.14773303, -0.12627223, -0.33053634,\n",
       "        -0.30799985,  0.4805188 ,  0.26717895, -0.13019001,  0.73795396,\n",
       "         0.6717404 ,  0.14484736,  0.00411977, -0.15547147,  0.9922641 ,\n",
       "        -0.1136213 ,  0.08443988, -0.3947429 , -0.2088909 , -0.27786538,\n",
       "        -0.14980827,  1.        ,  0.34231874,  0.3613973 , -0.99082226,\n",
       "        -0.51413363, -0.71788085,  0.99993867,  0.76502544, -0.6264718 ,\n",
       "         0.2581334 ,  0.49519208, -0.17145419,  0.56194997, -0.2513212 ,\n",
       "        -0.11177101,  0.12111699,  0.22903721,  0.9109344 , -0.56533426,\n",
       "        -0.97758406, -0.66193247,  0.386928  , -0.9286897 ,  0.9943321 ,\n",
       "        -0.42196098, -0.00190334, -0.33742502,  0.0747321 ,  0.23596409,\n",
       "        -0.07152915, -0.979273  , -0.04615286,  0.27184352,  0.95696056,\n",
       "         0.12474894, -0.47568178, -0.7792863 ,  0.1870456 ,  0.5068761 ,\n",
       "        -0.15982787, -0.9197969 ,  0.9653264 , -0.9360614 ,  0.58976   ,\n",
       "         0.9999971 ,  0.27343822, -0.4249156 ,  0.16374427, -0.18436855,\n",
       "         0.23309174, -0.5182082 ,  0.3738689 , -0.92004657, -0.34051123,\n",
       "        -0.00355964,  0.31695774, -0.04282033, -0.12225526,  0.66708255,\n",
       "         0.07041251, -0.46451423, -0.41823748,  0.07346758,  0.28815964,\n",
       "         0.7773426 , -0.2445588 , -0.05862296,  0.07476879, -0.05942297,\n",
       "        -0.8505434 , -0.31236762, -0.19764504, -0.99922055,  0.4248338 ,\n",
       "        -1.        , -0.03362766, -0.42772138, -0.21699734,  0.80393934,\n",
       "         0.45286766,  0.14340283, -0.7170234 , -0.37330875,  0.6906475 ,\n",
       "         0.75002444, -0.36423174, -0.13706143, -0.5825275 ,  0.11547901,\n",
       "         0.03673923,  0.14999934, -0.00771335,  0.7015939 , -0.1303533 ,\n",
       "         1.        ,  0.11667035, -0.41608322, -0.8470198 ,  0.0835982 ,\n",
       "        -0.09981066,  0.99999464, -0.646216  , -0.9420783 ,  0.15281644,\n",
       "        -0.33045208, -0.74796003,  0.37722367,  0.09444877, -0.50379443,\n",
       "        -0.7857379 ,  0.83126897,  0.72083366, -0.44810882,  0.5226194 ,\n",
       "        -0.18179753, -0.38859963,  0.15266582,  0.47945383,  0.9826104 ,\n",
       "         0.4547252 ,  0.7897179 ,  0.34203583, -0.11567927,  0.9573839 ,\n",
       "         0.17839381,  0.25928193,  0.23447396,  0.9999994 ,  0.254143  ,\n",
       "        -0.8731063 ,  0.23642002, -0.936138  , -0.34936237, -0.90479666,\n",
       "         0.24297662,  0.23376684,  0.79746324, -0.2198505 ,  0.9438262 ,\n",
       "        -0.21798192, -0.0504097 , -0.4071912 ,  0.22983092,  0.41053286,\n",
       "        -0.8844753 , -0.98313075, -0.98671764,  0.3410187 , -0.40536782,\n",
       "        -0.01127919,  0.26610786,  0.11019732,  0.28341094,  0.36625355,\n",
       "        -0.99999946,  0.91588324,  0.41519788,  0.33340412,  0.96491814,\n",
       "         0.44286513,  0.29763275,  0.27767837, -0.98001575, -0.9131004 ,\n",
       "        -0.27009523, -0.29661015,  0.5400345 ,  0.58291495,  0.76502186,\n",
       "         0.3700117 , -0.5483967 , -0.03317701,  0.03850706, -0.71237165,\n",
       "        -0.99299794,  0.50786304,  0.03157954, -0.8326599 ,  0.94599634,\n",
       "        -0.52662057, -0.12103602,  0.3405043 , -0.37129351,  0.64238554,\n",
       "         0.53712314,  0.23125397,  0.14156826,  0.12026066,  0.8848212 ,\n",
       "         0.8866778 ,  0.9859268 , -0.36247724,  0.593408  ,  0.04502391,\n",
       "         0.29941398,  0.8422201 , -0.9370656 ,  0.16663249,  0.13484627,\n",
       "        -0.39391977,  0.21360667, -0.3652009 , -0.76667744,  0.77564174,\n",
       "        -0.1918548 ,  0.4645821 , -0.34774533,  0.20555973, -0.3073274 ,\n",
       "        -0.31011721, -0.64540076, -0.34406647,  0.5407187 ,  0.07686026,\n",
       "         0.8505326 ,  0.53469986, -0.15126912, -0.54754287, -0.32432613,\n",
       "        -0.05807869, -0.91498166,  0.6998702 , -0.03013918,  0.32707176,\n",
       "         0.38370866, -0.08056671,  0.8152188 , -0.06771024, -0.27196622,\n",
       "        -0.24194837, -0.5622836 ,  0.53993064, -0.40496653, -0.57878256,\n",
       "        -0.4967698 ,  0.547109  ,  0.23547472,  0.99902666, -0.42913926,\n",
       "        -0.64989686, -0.22811674, -0.360373  ,  0.314816  , -0.4798108 ,\n",
       "        -0.9999995 ,  0.27542308,  0.17913108,  0.15085931, -0.485322  ,\n",
       "         0.31540367, -0.3466583 , -0.9431704 , -0.31041712,  0.30520597,\n",
       "         0.16880164, -0.4876838 , -0.71757984,  0.4369937 ,  0.26021788,\n",
       "         0.7228622 ,  0.7837656 ,  0.01374601,  0.47148573,  0.58936   ,\n",
       "        -0.12932348, -0.63150704,  0.8546795 ]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding([X_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        {'input_mask': (None 0           text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)      {'default': (None, 7 109482241   keras_layer[0][0]                \n",
      "                                                                 keras_layer[0][1]                \n",
      "                                                                 keras_layer[0][2]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           keras_layer_1[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            769         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.1,name = 'dropout')(outputs['pooled_output'])\n",
    "op = tf.keras.layers.Dense(1,activation = 'sigmoid', name = 'output')(dropout_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs = [text_input],outputs = op)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#callbacks = [EarlyStopping(monitor = 'val_accuracy',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/750 [..............................] - ETA: 56:22 - loss: 0.5738 - accuracy: 0.7215"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12464/3402383881.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\saumi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\saumi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\saumi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\saumi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\saumi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\saumi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\saumi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
